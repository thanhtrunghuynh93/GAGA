{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497af845",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f3b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GGNN(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.2):\n",
    "        super(GGNN, self).__init__()\n",
    "        self.proj = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.linearz0 = nn.Linear(out_features, out_features)\n",
    "        self.linearz1 = nn.Linear(out_features, out_features)\n",
    "        self.linearr0 = nn.Linear(out_features, out_features)\n",
    "        self.linearr1 = nn.Linear(out_features, out_features)\n",
    "        self.linearh0 = nn.Linear(out_features, out_features)\n",
    "        self.linearh1 = nn.Linear(out_features, out_features)\n",
    "        \n",
    "        if dropout > 0:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, adj, x):\n",
    "        if hasattr(self, 'dropout'): \n",
    "            x = self.dropout(x)\n",
    "        x = self.proj(x)\n",
    "        a = adj.matmul(x)\n",
    "\n",
    "        z0 = self.linearz0(a)\n",
    "        z1 = self.linearz1(x)\n",
    "        z = torch.sigmoid(z0 + z1)\n",
    "\n",
    "        r0 = self.linearr0(a)\n",
    "        r1 = self.linearr1(x)\n",
    "        r = torch.sigmoid(r0 + r1)\n",
    "\n",
    "        h0 = self.linearh0(a)\n",
    "        h1 = self.linearh1(r*x)\n",
    "        h = torch.tanh(h0 + h1)\n",
    "\n",
    "        feat = h*z + x*(1-z)\n",
    "    \n",
    "        return feat\n",
    "\n",
    "class GSL(nn.Module):\n",
    "    def __init__(self, rate):\n",
    "        super(GSL, self).__init__()\n",
    "        self.rate = rate\n",
    "\n",
    "    def forward(self, adj, score):\n",
    "        N = adj.shape[-1]\n",
    "        BATCH_SIZE = adj.shape[0]\n",
    "        num_preserve_node = int(self.rate * N)\n",
    "        _, indices = score.topk(num_preserve_node, 1)\n",
    "        indices = torch.squeeze(indices, dim=-1)\n",
    "        mask = torch.zeros([BATCH_SIZE, N, N]).to(adj.get_device())\n",
    "        for i in range(BATCH_SIZE):\n",
    "            mask[i].index_fill_(0, indices[i], 1)\n",
    "            mask[i].index_fill_(1, indices[i], 1)\n",
    "        adj = adj * mask\n",
    "        # feat = torch.tanh(score) * feat\n",
    "        return adj\n",
    "\n",
    "class GGNN_with_GSL(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, rate=0.8, dropout=0.2):\n",
    "        super(GGNN_with_GSL, self).__init__()\n",
    "\n",
    "        self.feat_prop1 = GGNN(input_dim, hidden_dim, dropout)\n",
    "        self.word_scorer1 = GGNN(hidden_dim, 1, dropout)\n",
    "        self.gsl1 = GSL(rate)\n",
    "\n",
    "        self.feat_prop2 = GGNN(hidden_dim, output_dim, dropout)\n",
    "        # self.word_scorer2 = GGNN(output_dim, 1, dropout)\n",
    "        # self.gsl2 = GSL(rate)\n",
    "    \n",
    "    def forward(self, adj, feat):\n",
    "        feat = self.feat_prop1(adj, feat)\n",
    "        score = self.word_scorer1(adj, feat)\n",
    "        adj_refined = self.gsl1(adj, score)\n",
    "        feat = self.feat_prop2(adj_refined, feat)\n",
    "        # score = self.word_scorer2(adj_refined, feat)\n",
    "        # adj_refined = self.gsl2(adj_refined, score)\n",
    "        return feat\n",
    "\n",
    "class ConcatNotEqualSelfAtt(nn.Module):\n",
    "    def __init__(self, inp_dim: int, hid_dim: int, num_heads: int = 1):\n",
    "        super().__init__()\n",
    "        self.inp_dim = inp_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.linear1 = nn.Linear(inp_dim, hid_dim, bias=False)\n",
    "        self.linear2 = nn.Linear(hid_dim, num_heads, bias=False)\n",
    "\n",
    "    def forward(self, left: torch.Tensor, right: torch.Tensor, mask: torch.Tensor):\n",
    "        \"\"\"\n",
    "        compute attention weights and apply it to `right` tensor\n",
    "        Parameters\n",
    "        ----------\n",
    "        left: `torch.Tensor` of shape (B, X) X is not necessarily equal to D\n",
    "        right: `torch.Tensor` of shape (B, L, D)\n",
    "        mask: `torch.Tensor` of shape (B, L), binary value, 0 is for pad\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        assert left.size(0) == right.size(0), \"Must same dimensions\"\n",
    "        assert len(left.size()) == 2 and len(right.size()) == 3\n",
    "        assert self.inp_dim == (left.size(-1) + right.size(-1))  # due to concat\n",
    "        B, L, D = right.size()\n",
    "        left_tmp = left.unsqueeze(1).expand(B, L, -1)  # (B, 1, X)\n",
    "        tsr = torch.cat([left_tmp, right], dim=-1)  # (B, L, 2D)\n",
    "        # start computing multi-head self-attention\n",
    "        tmp = torch.tanh(self.linear1(tsr))  # (B, L, out_dim)\n",
    "        linear_out = self.linear2(tmp)  # (B, L, C)\n",
    "        doc_mask = (mask == 0)  # (B, L) real tokens will be zeros and pad will have non zero (this is for softmax)\n",
    "        doc_mask = doc_mask.unsqueeze(-1).expand(B, L, self.num_heads)  # (B, L, C)\n",
    "        linear_out = linear_out.masked_fill(doc_mask, -np.inf)  # I learned from Attention is all you need\n",
    "        # we now can ensure padding tokens will not contribute to softmax\n",
    "        attention_weights = F.softmax(linear_out, dim=1)  # (B, L, C)\n",
    "        attended = torch.bmm(right.permute(0, 2, 1), attention_weights)  # (B, D, L) * (B, L, C) => (B, D, C)\n",
    "        return attended, attention_weights\n",
    "\n",
    "\n",
    "class GET_Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embedding=None, n_classes=2,\n",
    "                word_att_num_heads=5, evd_att_num_heads=5, \n",
    "                 max_doc_len=100, max_num_evd=30,\n",
    "                 rate=0.6, gnn_dropout=0.2):\n",
    "        \"\"\"\n",
    "        input_dim: The dimension of (Glove) word embeddings (300)\n",
    "        hidden_dim: The common hidden size of several GNN layers\n",
    "        embedding: Glove embedding matrix, if None, we initialize it ourselves\n",
    "        n_classess: number of clasess\n",
    "        word_att_num_heads: Number of attention heads \n",
    "            (attention of word embeddings in an evidence sentence according to the claim embeddings)\n",
    "        evd_att_num_heads: Number of attention heads\n",
    "            (attiention of evidence embeddings in a set of evidences according to claim embeddings)\n",
    "        max_doc_len: Maximum length of evidences\n",
    "        max_num_evd: Maximum number of evidences of a claim\n",
    "        rate: the keeping rate in GSL module (to keep only important edges)\n",
    "        gnn_dropout: Dropout used in GNN modules\n",
    "        \"\"\"\n",
    "        super(GET_Model, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_doc_len = max_doc_len\n",
    "        self.max_num_evd = max_num_evd\n",
    "        self.word_att_num_heads = word_att_num_heads\n",
    "        self.evd_att_num_heads = evd_att_num_heads\n",
    "        self.n_classes = n_classes\n",
    "        if embedding is None:\n",
    "            self.embedding = nn.Embedding(50000, self.input_dim)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding.from_pretrained(embedding, freeze=False)\n",
    "            \n",
    "        self.ggnn4claim = GGNN(self.input_dim, self.hidden_dim)\n",
    "        self.ggnn_with_gsl = GGNN_with_GSL(input_dim=self.input_dim, \n",
    "                              hidden_dim=self.hidden_dim, \n",
    "                              output_dim=self.hidden_dim, \n",
    "                              rate=rate, dropout=gnn_dropout)\n",
    "        # We concat word embeddings and claim embeddings so inp_dim = self.hidden_dim * 2\n",
    "        self.self_att_word = ConcatNotEqualSelfAtt(inp_dim=self.hidden_dim * 2, \n",
    "                                      hid_dim=self.hidden_dim, \n",
    "                                      num_heads=self.word_att_num_heads)\n",
    "        \n",
    "        # After word attention, embeddings of all heads are concatenated so the embedding size of evidence embeddings\n",
    "        # is self.word_att_num_heads * self.hidden_dim\n",
    "        self.self_att_evd = ConcatNotEqualSelfAtt(inp_dim=self.word_att_num_heads * self.hidden_dim + self.hidden_dim, \n",
    "                                     hid_dim=self.hidden_dim, \n",
    "                                     num_heads=self.evd_att_num_heads)\n",
    "        \n",
    "        # After evd attention, embeddings of all heads are concatenated so the embedding size of evidence embeddings\n",
    "        # is self.word_att_num_heads *  * self.evd_att_num_heads * self.hidden_dim        \n",
    "        evd_input_size = self.word_att_num_heads * self.evd_att_num_heads * self.hidden_dim + self.hidden_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(evd_input_size, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.n_classes)\n",
    "        )\n",
    "\n",
    "    def _query_embedding(self, query, adj, query_mask):\n",
    "        \"\"\"\n",
    "        query: tensor of size (BATCH_SIZE, MAX_CLAIM_LEN) \n",
    "        adj: tensor of size (BATCH_SIZE, MAX_CLAIM_LEN, MAX_CLAIM_LEN)\n",
    "        query_mask: tensor of size (BATCH_SIZE, MAX_CLAIM_LEN)\n",
    "        \"\"\"\n",
    "        # Do the look up table\n",
    "        embed_query = self.embedding(query)\n",
    "        \n",
    "        # Get the word embeddings of the claim\n",
    "        query_gnn_hiddens = self.ggnn4claim(adj.float(), embed_query)\n",
    "        \n",
    "        # Basically, the claim embedding is the average of its word embeddings\n",
    "        sum_query_repr = (query_gnn_hiddens * query_mask.unsqueeze(-1)).sum(1)\n",
    "        query_repr = sum_query_repr / query_mask.sum(1, keepdim=True)\n",
    "        assert query_repr.shape[-1] == self.hidden_dim\n",
    "        return query_repr\n",
    "    \n",
    "    def _expand_query_embedding(self, query_repr, evd_count_per_query):\n",
    "        \"\"\"\n",
    "        query_repr: tensor of (BATCH_SIZE, HIDDEN_DIM)\n",
    "        evd_count_per_query: tensor (BATCH_SIZE, ): store the number of evidences for each claim\n",
    "        -> output: tensor of size (sum(evd_count_per_query, HIDDEN_DIM))\n",
    "        \"\"\"\n",
    "        expanded_query_repr = []\n",
    "        for num_evd, tsr in zip(evd_count_per_query, query_repr):\n",
    "            tmp = tsr.clone()\n",
    "            tsr = tmp.expand(num_evd, self.hidden_dim)\n",
    "            expanded_query_repr.append(tsr)\n",
    "        expanded_query_repr = torch.cat(expanded_query_repr, dim = 0)\n",
    "        return expanded_query_repr\n",
    "\n",
    "    def _doc_embedding(self, doc, doc_adj):\n",
    "        \"\"\"\n",
    "        doc: tensor size = (sum(evd_count_per_query), MAX_DOC_LEN)\n",
    "        doc_adj : tensor size = (sum(evd_count_per_query), MAX_DOC_LEN, MAX_DOC_LEN)\n",
    "        \n",
    "        -> output: tensor of size = (sum(evd_count_per_query), HIDDEN_DIM)\n",
    "        \"\"\"\n",
    "        embed_doc = self.embedding(doc)\n",
    "        doc_out_ggnn = self.ggnn_with_gsl(doc_adj.float(), embed_doc)\n",
    "        assert doc_out_ggnn.shape[1:] == (self.max_doc_len, self.hidden_dim)\n",
    "        return doc_out_ggnn\n",
    "    \n",
    "    def _word_attention_doc_embedding(self, expanded_query_repr, doc_out_ggnn, doc_mask):\n",
    "        \"\"\"\n",
    "        expanded_query_repr : size (sum(evd_count_per_query, HIDDEN_DIM))\n",
    "        doc_out_ggnn: size (sum(evd_count_per_query), HIDDEN_DIM)\n",
    "        doc_mask : (sum(evd_count_per_query), HIDDEN_DIM) \n",
    "        \"\"\"\n",
    "        avg, _ = self.self_att_word(expanded_query_repr, doc_out_ggnn, doc_mask)\n",
    "        avg = torch.flatten(avg, start_dim=1)\n",
    "        assert avg.shape == (doc_out_ggnn.shape[0], self.word_att_num_heads * self.hidden_dim)\n",
    "        return avg\n",
    "    \n",
    "    def _pad_doc_embedding(self, attentioned_doc_repr, evd_count_per_query):\n",
    "        last = 0\n",
    "        padded_doc_repr = []\n",
    "        for idx in range(evd_count_per_query.shape[0]):\n",
    "            num_evd = evd_count_per_query[idx].item()\n",
    "            hidden_vectors = attentioned_doc_repr[last: last + num_evd]  # (n1, H)\n",
    "            padded = F.pad(hidden_vectors, (0, 0, 0, self.max_num_evd - num_evd), \"constant\", 0)\n",
    "            padded_doc_repr.append(padded)\n",
    "            last += num_evd\n",
    "        padded_doc_repr = torch.stack(padded_doc_repr, dim=0)\n",
    "        assert padded_doc_repr.shape == (evd_count_per_query.shape[0], \n",
    "                                         self.max_num_evd, \n",
    "                                         self.word_att_num_heads * self.hidden_dim)\n",
    "        return padded_doc_repr\n",
    "\n",
    "    def _evd_attention_doc_embedding(self, query_repr, padded_doc_repr, evd_count_per_query):\n",
    "        batch_size = evd_count_per_query.shape[0]\n",
    "        doc_mask = torch.arange(self.max_num_evd).repeat(batch_size, 1).to(query_repr.get_device())\n",
    "        doc_mask = doc_mask < evd_count_per_query.unsqueeze(1)\n",
    "        doc_mask = doc_mask.float()\n",
    "        attended_avg, _ = self.self_att_evd(query_repr, padded_doc_repr, doc_mask)\n",
    "        avg = torch.flatten(attended_avg, start_dim=1)\n",
    "        assert avg.shape == (batch_size, self.word_att_num_heads * self.evd_att_num_heads * self.hidden_dim)\n",
    "        \n",
    "        return avg \n",
    "    \n",
    "    def forward(self, query, query_adj, query_mask, doc, doc_adj, doc_mask, evd_count_per_query):\n",
    "        \"\"\"\n",
    "        query: tensor of word ids, size (BATCH_SIZE, MAX_CLAIM_LEN)\n",
    "        query_adj: tensor, size (BATCH_SIZE, MAX_CLAIM_LEN, MAX_CLAIM_LEN)\n",
    "        query_mask: tensor, size (BATCH_SIZE, MAX_CLAIM_LEN)\n",
    "        doc: tensor of word ids size (sum(evd_count_per_query), MAX_DOC_LEN)\n",
    "        doc_adj: tensor of word ids size (sum(evd_count_per_query), MAX_DOC_LEN, MAX_DOC_LEN)\n",
    "        doc_mask: tensor of word ids size (sum(evd_count_per_query), MAX_DOC_LEN)\n",
    "        evd_count_per_query: (BATCH_SIZE, )\n",
    "        \"\"\"\n",
    "        # (batch_size, hidden_dim)\n",
    "        query_repr = self._query_embedding(query, query_adj, query_mask)\n",
    "        \n",
    "        #(sum(evd_count_per_query), hidden_dim)\n",
    "        expanded_query_repr = self._expand_query_embedding(query_repr, evd_count_per_query)\n",
    "        \n",
    "        #(sum(evd_count_per_query), max_doc_len, hidden_dim) \n",
    "        doc_out_ggnn = self._doc_embedding(doc, doc_adj)\n",
    "        \n",
    "        #(sum(evd_count_per_query), word_att_num_heads * hidden_dim) \n",
    "        attentioned_doc_repr = self._word_attention_doc_embedding(expanded_query_repr, doc_out_ggnn, doc_mask)\n",
    "\n",
    "        # (batch_size, max_num_evd, word_att_num_heads * hidden_dim) \n",
    "        padded_doc_repr = self._pad_doc_embedding(attentioned_doc_repr, evd_count_per_query)\n",
    "\n",
    "        doc_repr = self._evd_attention_doc_embedding(query_repr, padded_doc_repr, evd_count_per_query)\n",
    "        \n",
    "        query_doc_repr = torch.cat([query_repr, doc_repr], dim=-1)\n",
    "        logit = self.mlp(query_doc_repr)\n",
    "        return logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd0d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfbd11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./formatted_data/declare/Snopes/mapped_data/5fold/train_0.tsv', delimiter='\\t')\n",
    "df_test = pd.read_csv('./formatted_data/declare/Snopes/mapped_data/5fold/test_0.tsv', delimiter='\\t')\n",
    "df_dev = pd.read_csv('./formatted_data/declare/Snopes/mapped_data/dev.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318ca48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are at most 28 evidences per claim\n",
      "There are at most 26 evidences per claim\n",
      "There are at most 26 evidences per claim\n"
     ]
    }
   ],
   "source": [
    "for df in [df_train, df_test, df_dev]:\n",
    "    print(\"There are at most {} evidences per claim\"\\\n",
    "          .format(df.groupby('id_left').count().cred_label.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0f25f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_left</th>\n",
       "      <th>cred_label</th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim_text</th>\n",
       "      <th>claim_source</th>\n",
       "      <th>id_right</th>\n",
       "      <th>evidence</th>\n",
       "      <th>evidence_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2586</td>\n",
       "      <td>False</td>\n",
       "      <td>102-lb-shrimp</td>\n",
       "      <td>image depicts 102 lb shrimp caught near homosa...</td>\n",
       "      <td></td>\n",
       "      <td>17409</td>\n",
       "      <td>the big picture behind a recent study on sparr...</td>\n",
       "      <td>flipboard.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2762</td>\n",
       "      <td>False</td>\n",
       "      <td>14-year-old-pregnant-flu-shot</td>\n",
       "      <td>girl became pregnant receiving flu shot</td>\n",
       "      <td></td>\n",
       "      <td>18619</td>\n",
       "      <td>texas girl impregnated by flu summary of a tex...</td>\n",
       "      <td>www.truthorfiction.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2762</td>\n",
       "      <td>False</td>\n",
       "      <td>14-year-old-pregnant-flu-shot</td>\n",
       "      <td>girl became pregnant receiving flu shot</td>\n",
       "      <td></td>\n",
       "      <td>18620</td>\n",
       "      <td>between satire about us did a 14 year old real...</td>\n",
       "      <td>www.thatsfake.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2762</td>\n",
       "      <td>False</td>\n",
       "      <td>14-year-old-pregnant-flu-shot</td>\n",
       "      <td>girl became pregnant receiving flu shot</td>\n",
       "      <td></td>\n",
       "      <td>18621</td>\n",
       "      <td>old virgin falls pregnant after flu shot login...</td>\n",
       "      <td>topratedviral.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2762</td>\n",
       "      <td>False</td>\n",
       "      <td>14-year-old-pregnant-flu-shot</td>\n",
       "      <td>girl became pregnant receiving flu shot</td>\n",
       "      <td></td>\n",
       "      <td>18622</td>\n",
       "      <td>settings show signatures loading thread oct 24...</td>\n",
       "      <td>www.whattoexpect.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_left  cred_label                       claim_id  \\\n",
       "0     2586       False                  102-lb-shrimp   \n",
       "1     2762       False  14-year-old-pregnant-flu-shot   \n",
       "2     2762       False  14-year-old-pregnant-flu-shot   \n",
       "3     2762       False  14-year-old-pregnant-flu-shot   \n",
       "4     2762       False  14-year-old-pregnant-flu-shot   \n",
       "\n",
       "                                          claim_text claim_source  id_right  \\\n",
       "0  image depicts 102 lb shrimp caught near homosa...                  17409   \n",
       "1            girl became pregnant receiving flu shot                  18619   \n",
       "2            girl became pregnant receiving flu shot                  18620   \n",
       "3            girl became pregnant receiving flu shot                  18621   \n",
       "4            girl became pregnant receiving flu shot                  18622   \n",
       "\n",
       "                                            evidence         evidence_source  \n",
       "0  the big picture behind a recent study on sparr...           flipboard.com  \n",
       "1  texas girl impregnated by flu summary of a tex...  www.truthorfiction.com  \n",
       "2  between satire about us did a 14 year old real...       www.thatsfake.com  \n",
       "3  old virgin falls pregnant after flu shot login...       topratedviral.com  \n",
       "4  settings show signatures loading thread oct 24...    www.whattoexpect.com  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaed9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, df, max_claim_len=30, max_evd_len=100):\n",
    "        self.max_claim_len = max_claim_len\n",
    "        self.max_evd_len = max_evd_len\n",
    "        self._read_text(df)\n",
    "        self.text_corpus = None\n",
    "        self.src_corpus = None\n",
    "    \n",
    "    def _laplacian_normalize(self, adj):\n",
    "        \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "        adj = sp.coo_matrix(adj)\n",
    "        rowsum = np.array(adj.sum(1))\n",
    "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "        return (adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt)).A\n",
    "\n",
    "    def _text_transform(self, input_, n):\n",
    "        _MATCH_PUNC = re.compile(r'[^\\w\\s]')\n",
    "        x = nltk.word_tokenize(input_)\n",
    "        x = [token.lower() for token in x]\n",
    "        x = [token for token in x if not _MATCH_PUNC.search(token)]\n",
    "        return x[: n]\n",
    "\n",
    "    def _read_text(self, df):        \n",
    "        self.claim_evidences = defaultdict(list)\n",
    "        self.claim_ids = {}\n",
    "        self.claim_texts, self.labels = [], []\n",
    "        for i, (_, row) in tqdm(enumerate(df.iterrows()), desc='Read text'):\n",
    "            if row.id_left not in self.claim_ids:\n",
    "                self.claim_ids[row.id_left] = len(self.claim_ids)\n",
    "                self.claim_texts.append(row.claim_text)\n",
    "                self.labels.append(row.cred_label)\n",
    "            self.claim_evidences[self.claim_ids[row.id_left]].append(i)\n",
    "        self.evd_sources = df.evidence_source.apply(lambda x: x.strip()).values.tolist()\n",
    "        self.evd_texts = df.evidence.values.tolist()\n",
    "        \n",
    "        self.tokenized_claim_texts = [self._text_transform(text, self.max_claim_len) for text in tqdm(self.claim_texts, desc='Transform claim')]\n",
    "        self.tokenized_evd_texts = [self._text_transform(text, self.max_evd_len) for text in tqdm(self.evd_texts, desc='Transform evidences')]\n",
    "    \n",
    "    def get_text_corpus(self, rebuild=False):\n",
    "        if self.text_corpus is not None and not rebuild:\n",
    "            return self.text_corpus\n",
    "        self.text_corpus = set()\n",
    "        for tokenized_claim_text in self.tokenized_claim_texts:\n",
    "            self.text_corpus.update(tokenized_claim_text)\n",
    "        for tokenized_evd_text in self.tokenized_evd_texts:\n",
    "            self.text_corpus.update(tokenized_evd_text)\n",
    "            \n",
    "        return self.text_corpus\n",
    "    \n",
    "    def get_src_corpus(self):\n",
    "        return set(self.evd_sources)\n",
    "\n",
    "    def encoding(self, vocab, evd_vocab=None):\n",
    "        self.encoded_claim_texts = [vocab.transform(x) for x in tqdm(self.tokenized_claim_texts)]\n",
    "        self.encoded_evd_texts = [vocab.transform(x) for x in tqdm(self.tokenized_evd_texts)]\n",
    "        if evd_vocab is not None:\n",
    "            self.encoded_evidence_source = [evd_vocab.transform(x) for x in self.evd_sources]\n",
    "           \n",
    "    def _convert_text(self, raw_text, fixed_length=30, window_size=5):\n",
    "        words_list = list(set(raw_text))       # remove duplicate words in original order\n",
    "        words_list.sort(key=raw_text.index)\n",
    "        words2id = {word: id for id, word in enumerate(words_list)}\n",
    "\n",
    "        length_, length = len(words2id), len(raw_text)\n",
    "        neighbours = [set() for _ in range(length_)]\n",
    "        # window_size = window_size if fixed_length == 30 else 300\n",
    "        for i, word in enumerate(raw_text):\n",
    "            for j in range(max(i-window_size+1, 0), min(i+window_size, length)):\n",
    "                neighbours[words2id[word]].add(words2id[raw_text[j]])\n",
    "\n",
    "        # gat graph\n",
    "        adj = [[1 if (max(i, j) < length_) and (j in neighbours[i]) else 0 for j in range(fixed_length)]\n",
    "               for i in range(fixed_length)]\n",
    "        words_list.extend([0 for _ in range(fixed_length-length_)])\n",
    "        adj = self._laplacian_normalize(np.array(adj))\n",
    "        return words_list, adj\n",
    "    \n",
    "    def build_data(self, window_size=5): \n",
    "        self.claim_text, self.claim_adj = [], []\n",
    "        for encoded_claim_text in tqdm(self.encoded_claim_texts):\n",
    "            text_, adj = self._convert_text(encoded_claim_text, self.max_claim_len, window_size)\n",
    "            self.claim_text.append(np.array(text_))\n",
    "            self.claim_adj.append(np.array(adj))\n",
    "\n",
    "        self.evd_text, self.evd_adj = [], []\n",
    "        for encoded_evd_text in tqdm(self.encoded_evd_texts):\n",
    "            text_, adj = self._convert_text(encoded_evd_text, self.max_evd_len, window_size)\n",
    "            self.evd_text.append(np.array(text_))\n",
    "            self.evd_adj.append(np.array(adj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47422df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read text: 21074it [00:01, 17527.46it/s]\n",
      "Transform claim: 100%|██████████| 3126/3126 [00:00<00:00, 11812.16it/s]\n",
      "Transform evidences: 100%|██████████| 21074/21074 [00:06<00:00, 3311.49it/s]\n",
      "Read text: 2756it [00:00, 17193.71it/s]\n",
      "Transform claim: 100%|██████████| 433/433 [00:00<00:00, 11460.79it/s]\n",
      "Transform evidences: 100%|██████████| 2756/2756 [00:00<00:00, 3360.59it/s]\n",
      "Read text: 5412it [00:00, 17524.39it/s]\n",
      "Transform claim: 100%|██████████| 782/782 [00:00<00:00, 12379.12it/s]\n",
      "Transform evidences: 100%|██████████| 5412/5412 [00:01<00:00, 3269.57it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = Data(df_train)\n",
    "dev_data = Data(df_dev)\n",
    "test_data = Data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917deeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "\n",
    "    def __init__(self, pad_value: str = '<PAD>', oov_value: str = '<OOV>'):\n",
    "        \"\"\"Vocabulary unit initializer.\"\"\"\n",
    "        self._pad = pad_value\n",
    "        self._oov = oov_value\n",
    "        self._state = {}\n",
    "        self._state['term_index'] = self.TermIndex()\n",
    "        self._state['index_term'] = dict()\n",
    "\n",
    "    class TermIndex(dict):\n",
    "        \"\"\"Map term to index.\"\"\"\n",
    "\n",
    "        def __missing__(self, key):\n",
    "            \"\"\"Map out-of-vocabulary terms to index 1.\"\"\"\n",
    "            return 1\n",
    "\n",
    "    def fit(self, tokens: set):\n",
    "        \"\"\"Build a :class:`TermIndex` and a :class:`IndexTerm`.\"\"\"\n",
    "        self._state['term_index'][self._pad] = 0\n",
    "        self._state['term_index'][self._oov] = 1\n",
    "        self._state['index_term'][0] = self._pad\n",
    "        self._state['index_term'][1] = self._oov\n",
    "        for index, term in enumerate(sorted(tokens)):\n",
    "            self._state['term_index'][term] = index + 2\n",
    "            self._state['index_term'][index + 2] = term\n",
    "\n",
    "    def transform(self, input_: list) -> list:\n",
    "        \"\"\"Transform a list of tokens to corresponding indices.\"\"\"\n",
    "        return [self._state['term_index'][token] for token in input_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e57f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary()\n",
    "vocab.fit(train_data.get_text_corpus())\n",
    "evd_vocab = Vocabulary()\n",
    "evd_vocab.fit(train_data.get_src_corpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63eb3f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:05, 69727.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word hit: (49879, 49881) 99.99599045728834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "term_index = vocab._state['term_index']\n",
    "embedding_data = {}\n",
    "output_dim = 0\n",
    "count_word_hit = 0\n",
    "file_path = '/home/datht/glove.6B.300d.txt'\n",
    "with open(file_path, 'r', encoding = \"utf-8\") as f:\n",
    "    output_dim = len(f.readline().rstrip().split(' ')) - 1\n",
    "    f.seek(0)\n",
    "    for line in tqdm(f):\n",
    "        current_line = line.rstrip().split(' ')\n",
    "        if current_line[0] not in term_index: continue\n",
    "        embedding_data[current_line[0]] = current_line[1:]\n",
    "        count_word_hit += 1\n",
    "\n",
    "    print(\"Word hit: \" + str((count_word_hit, len(term_index))) + \" \" + str(count_word_hit / len(term_index) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79776050",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(term_index)\n",
    "matrix = np.empty((input_dim, output_dim))\n",
    "valid_keys = embedding_data.keys()\n",
    "for term, index in sorted(term_index.items(), key = lambda x: x[1]):  # Starting the smallest index to the largest\n",
    "    if term in valid_keys:\n",
    "        matrix[index] = embedding_data[term]\n",
    "    else:\n",
    "        matrix[index] = np.random.uniform(-0.2, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00e684ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3126/3126 [00:00<00:00, 303532.60it/s]\n",
      "100%|██████████| 21074/21074 [00:00<00:00, 56149.14it/s]\n",
      "100%|██████████| 433/433 [00:00<00:00, 155225.10it/s]\n",
      "100%|██████████| 2756/2756 [00:00<00:00, 53478.83it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 179085.22it/s]\n",
      "100%|██████████| 5412/5412 [00:00<00:00, 55160.99it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data.encoding(vocab, evd_vocab)\n",
    "dev_data.encoding(vocab, evd_vocab)\n",
    "test_data.encoding(vocab, evd_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d5e3ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3126 [00:00<?, ?it/s]/tmp/ipykernel_28731/3868473062.py:13: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
      "100%|██████████| 3126/3126 [00:03<00:00, 995.89it/s] \n",
      "100%|██████████| 21074/21074 [01:04<00:00, 328.64it/s]\n",
      "100%|██████████| 433/433 [00:00<00:00, 1088.26it/s]\n",
      "100%|██████████| 2756/2756 [00:08<00:00, 329.72it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1092.63it/s]\n",
      "100%|██████████| 5412/5412 [00:16<00:00, 326.47it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data.build_data()\n",
    "dev_data.build_data()\n",
    "test_data.build_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c38f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, n_evd_per_claim=30):\n",
    "        self.claim_text = data.claim_text\n",
    "        self.claim_adj = data.claim_adj\n",
    "        self.evd_text = data.evd_text\n",
    "        self.evd_adj = data.evd_adj\n",
    "        self.labels = data.labels\n",
    "        self.claim_evidences = data.claim_evidences\n",
    "        self.n_evd_per_claim = n_evd_per_claim\n",
    "\n",
    "    def _text_to_mask(self, text):\n",
    "        return (text > 0).astype(int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        query = self.claim_text[idx]\n",
    "        query_adj = self.claim_adj[idx]\n",
    "        query_mask = self._text_to_mask(query)\n",
    "        label = self.labels[idx]\n",
    "        n_evds = len(self.claim_evidences[idx])\n",
    "        evds, evd_adjs, evd_masks = [], [], []\n",
    "        for evd_idx in self.claim_evidences[idx]:\n",
    "            evds.append(self.evd_text[evd_idx])\n",
    "            evd_adjs.append(self.evd_adj[evd_idx])\n",
    "            evd_masks.append(self._text_to_mask(evds[-1]))\n",
    "        evds = np.stack(evds)\n",
    "        evd_adjs = np.stack(evd_adjs)\n",
    "        evd_masks = np.stack(evd_masks)\n",
    "\n",
    "        return query, query_adj, query_mask, evds, evd_adjs, evd_masks, n_evds, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f90a0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_data)\n",
    "dev_dataset = MyDataset(dev_data)\n",
    "test_dataset = MyDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "121d173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    query_list, query_adj_list, query_mask_list, evd_list, evd_adj_list, evd_mask_list, n_evd_list, label_list \\\n",
    "    = [], [], [], [], [], [], [], []\n",
    "\n",
    "    for query, query_adj, query_mask, evds, evd_adjs, evd_masks, n_evds, label in batch:\n",
    "        query_list.append(query)\n",
    "        query_adj_list.append(query_adj)\n",
    "        query_mask_list.append(query_mask)\n",
    "        evd_list.append(evds)\n",
    "        evd_adj_list.append(evd_adjs)\n",
    "        evd_mask_list.append(evd_masks)\n",
    "        n_evd_list.append(n_evds)\n",
    "        label_list.append(label)\n",
    "    \n",
    "    query_list = torch.LongTensor(np.stack(query_list))\n",
    "    query_adj_list = torch.FloatTensor(np.stack(query_adj_list))\n",
    "    query_mask_list = torch.LongTensor(np.stack(query_mask_list))\n",
    "\n",
    "    evd_list = torch.LongTensor(np.vstack(evd_list))\n",
    "    evd_adj_list = torch.FloatTensor(np.vstack(evd_adj_list))\n",
    "    evd_mask_list = torch.LongTensor(np.vstack(evd_mask_list))\n",
    "    \n",
    "    n_evd_list = torch.LongTensor(n_evd_list)\n",
    "    label_list = torch.LongTensor(label_list)\n",
    "    return (query_list, query_adj_list, query_mask_list, evd_list, evd_adj_list, evd_mask_list, n_evd_list), label_list\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, collate_fn=collate_batch, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=8, collate_fn=collate_batch, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, collate_fn=collate_batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e703aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model = GET_Model(input_dim=300, hidden_dim=300,\\\n",
    "                      embedding=torch.FloatTensor(matrix),\\\n",
    "                      max_num_evd=30, word_att_num_heads=5,\n",
    "                     evd_att_num_heads=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd4d1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(get_model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfffbf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:55<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.201576333493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:56<00:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.24982149899006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x = tuple([i.cuda() for i in x])\n",
    "        y = y.cuda()\n",
    "        logits = get_model(*x)\n",
    "        loss = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(get_model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # break\n",
    "    print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ea3b27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:09<00:00, 10.13it/s]\n"
     ]
    }
   ],
   "source": [
    "get_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_logits = []\n",
    "    all_trues = []\n",
    "    for x, y in tqdm(test_loader):\n",
    "        x = tuple([i.cuda() for i in x])\n",
    "        y = y.cuda()\n",
    "        logits = get_model(*x)\n",
    "        all_logits.append(logits)\n",
    "        all_trues.append(y)\n",
    "all_trues = torch.cat(all_trues).detach().cpu().numpy()\n",
    "all_logits = torch.cat(all_logits, dim=0)\n",
    "predicts = all_logits.argmax(dim=1).detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d940e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7902813299232736\n",
      "0.6891771366527067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(all_trues, predicts, average=\"micro\"))\n",
    "print(f1_score(all_trues, predicts, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retriever",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
